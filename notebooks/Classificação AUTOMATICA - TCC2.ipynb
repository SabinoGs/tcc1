{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import bson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sabinogs/projetos/tcc/dump/test/reviews.bson', 'rb') as b:\n",
    "    df = pd.DataFrame(bson.decode_all(b.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "comentarios = df[df['requirement_type'].isin(['non-functional requirement', 'other', 'functional requirement'])]\n",
    "df = df[['reviewText','summary','requirement_type']]\n",
    "df['pre'] = pd.Series()\n",
    "comentarios = comentarios[['reviewText','summary','requirement_type']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4784, 3)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_sentences(sentences):\n",
    "    word_without_stop = list()\n",
    "    for sent in sentences:\n",
    "        aux = list()\n",
    "        for word in sent:\n",
    "            if word not in stopwords.words('english'):\n",
    "                aux.append(word)\n",
    "        word_without_stop.append(aux)\n",
    "    \n",
    "    return word_without_stop\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    return [word for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "def lemmatize_sentences(sentences):\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    lw = list()\n",
    "    for sent in sentences:\n",
    "        aux = list()\n",
    "        for word in sent:\n",
    "            aux.append(lemma.lemmatize(word))\n",
    "        lw.append(aux)\n",
    "    \n",
    "    return lw\n",
    "\n",
    "def lemmatize_it(words):\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    return [lemma.lemmatize(word) for word in words]\n",
    "\n",
    "\n",
    "def remove_pon(doc):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(doc)\n",
    "\n",
    "def _stem_it(doc):\n",
    "    stem = PorterStemmer()\n",
    "    return [stem.stem(word) for word in doc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = comentarios['reviewText'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it)\n",
    "pre_summary = comentarios['summary'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = pre + pre_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>requirement_type</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How dissapointing..downloaded and found it doe...</td>\n",
       "      <td>Extreme Dissappointment</td>\n",
       "      <td>non-functional requirement</td>\n",
       "      <td>how dissapoint download and found it doe not a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is great for kids my two year old son lov...</td>\n",
       "      <td>great</td>\n",
       "      <td>other</td>\n",
       "      <td>thi is great for kid my two year old son love ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Loves the song, so he really couldn't wait to ...</td>\n",
       "      <td>Really cute</td>\n",
       "      <td>non-functional requirement</td>\n",
       "      <td>love the song so he realli couldn t wait to pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My three year old Plays this game the most he ...</td>\n",
       "      <td>Five little monkeys</td>\n",
       "      <td>other</td>\n",
       "      <td>My three year old play thi game the most he lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a Speech language pathology Assistant I hav...</td>\n",
       "      <td>My patients request this app everytime they se...</td>\n",
       "      <td>other</td>\n",
       "      <td>As a speech languag patholog assist I have a v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  How dissapointing..downloaded and found it doe...   \n",
       "1  This is great for kids my two year old son lov...   \n",
       "2  Loves the song, so he really couldn't wait to ...   \n",
       "3  My three year old Plays this game the most he ...   \n",
       "4  As a Speech language pathology Assistant I hav...   \n",
       "\n",
       "                                             summary  \\\n",
       "0                            Extreme Dissappointment   \n",
       "1                                              great   \n",
       "2                                        Really cute   \n",
       "3                                Five little monkeys   \n",
       "4  My patients request this app everytime they se...   \n",
       "\n",
       "             requirement_type  \\\n",
       "0  non-functional requirement   \n",
       "1                       other   \n",
       "2  non-functional requirement   \n",
       "3                       other   \n",
       "4                       other   \n",
       "\n",
       "                                                 pre  \n",
       "0  how dissapoint download and found it doe not a...  \n",
       "1  thi is great for kid my two year old son love ...  \n",
       "2  love the song so he realli couldn t wait to pl...  \n",
       "3  My three year old play thi game the most he lo...  \n",
       "4  As a speech languag patholog assist I have a v...  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios['pre'] = pre\n",
    "comentarios['pre'] = comentarios['pre'].apply(lambda x: ' '.join(x))\n",
    "comentarios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = comentarios[comentarios['requirement_type'] != 'other']\n",
    "# c['pre'] = c['pre'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "\n",
    "Para maior referencia, olhe os links acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = c['pre'].tolist()\n",
    "y = c['requirement_type'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_classifier.fit(X_train,y_train)\n",
    "predicted = text_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "    functional requirement       0.64      1.00      0.78       273\n",
      "non-functional requirement       1.00      0.02      0.04       159\n",
      "\n",
      "                 micro avg       0.64      0.64      0.64       432\n",
      "                 macro avg       0.82      0.51      0.41       432\n",
      "              weighted avg       0.77      0.64      0.51       432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Um Classificador para identificar todas as categorias (Experimento 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                         3347\n",
       "functional requirement         928\n",
       "non-functional requirement     509\n",
       "Name: requirement_type, dtype: int64"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comentarios['requirement_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            precision    recall  f1-score   support\n",
      "\n",
      "    functional requirement       1.00      0.01      0.03       288\n",
      "non-functional requirement       0.00      0.00      0.00       149\n",
      "                     other       0.70      1.00      0.82       999\n",
      "\n",
      "                 micro avg       0.70      0.70      0.70      1436\n",
      "                 macro avg       0.57      0.34      0.28      1436\n",
      "              weighted avg       0.69      0.70      0.58      1436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabinogs/.virtualenvs/explore/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X = comentarios['pre'].tolist()\n",
    "y = comentarios['requirement_type'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "text_classifier_exp1 = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_classifier_exp1.fit(X_train,y_train)\n",
    "predicted_exp1 = text_classifier_exp1.predict(X_test)\n",
    "print(classification_report(y_test, predicted_exp1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nessa seção criarei um classificador para cada Requisito\n",
    "\n",
    "\n",
    "\n",
    "Isso se dá pela necessidade de aumentar o desempenho do classificador. Para isso, será criado 3 classificadores que: \n",
    "\n",
    "1. Identificará se um comentário é do tipo \"Funcional\" ou não\n",
    "2. Identificará se um comentário é do tipo \"Não Funcional\" ou não\n",
    "3. Identificará se um comentário é do tipo \"Outro\" ou não\n",
    "\n",
    "\n",
    "Observe o uso do `DataFrame.copy()`. Isso deve-se ao fato de que ao realizar uma atribuição de dataframe `novoDF = velho` copiamos apenas a referência e isso implicará que mudar uma coisa no `novoDF` muda tbm no `velho`. \n",
    "\n",
    "\n",
    "\n",
    "Ref: \n",
    "\n",
    "1. https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.copy.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nao_funcionais = comentarios.copy(deep=True)\n",
    "outros = comentarios.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataset(documento, requirement_type):\n",
    "    if documento == requirement_type:\n",
    "        return 'sim'\n",
    "    else:\n",
    "        return 'nao'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "nao_funcionais['requirement_type'] = nao_funcionais['requirement_type'].apply(\n",
    "    lambda x: transform_dataset(x,'non-functional requirement')\n",
    ")\n",
    "\n",
    "\n",
    "outros['requirement_type'] = outros['requirement_type'].apply(\n",
    "    lambda x: transform_dataset(x,'other')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento 2\n",
    "\n",
    "## Dataset e Classificador para FUNCIONAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcionais = comentarios.copy(deep=True)\n",
    "funcionais['requirement_type'] = funcionais['requirement_type'].apply(\n",
    "    lambda x: transform_dataset(x,'functional requirement')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao    3856\n",
       "sim     928\n",
       "Name: requirement_type, dtype: int64"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funcionais['requirement_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nao       0.80      1.00      0.89      1148\n",
      "         sim       1.00      0.01      0.01       288\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1436\n",
      "   macro avg       0.90      0.50      0.45      1436\n",
      "weighted avg       0.84      0.80      0.71      1436\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_pre_review = funcionais['reviewText'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "_pre_summary = funcionais['summary'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "\n",
    "pre = _pre_review + _pre_summary\n",
    "funcionais['pre'] = pre\n",
    "funcionais['pre'] = funcionais['pre'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "X_funcionais = funcionais['pre'].tolist()\n",
    "y_funcionais = funcionais['requirement_type'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_funcionais, y_funcionais, test_size=0.3, random_state=42)\n",
    "\n",
    "text_classifier_funcionais = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_classifier_funcionais.fit(X_train, y_train)\n",
    "predicted_funcionais = text_classifier_funcionais.predict(X_test)\n",
    "print(classification_report(y_test, predicted_funcionais))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset e Classificador para NAO FUNCIONAIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "nao_funcionais = comentarios.copy(deep=True)\n",
    "nao_funcionais['requirement_type'] = nao_funcionais['requirement_type'].apply(\n",
    "    lambda x: transform_dataset(x,'non-functional requirement')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao    4275\n",
       "sim     509\n",
       "Name: requirement_type, dtype: int64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nao_funcionais['requirement_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nao       0.90      1.00      0.95      1287\n",
      "         sim       0.00      0.00      0.00       149\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1436\n",
      "   macro avg       0.45      0.50      0.47      1436\n",
      "weighted avg       0.80      0.90      0.85      1436\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sabinogs/.virtualenvs/explore/lib/python3.5/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "_pre_review = nao_funcionais['reviewText'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "_pre_summary = nao_funcionais['summary'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "\n",
    "pre = _pre_review + _pre_summary\n",
    "nao_funcionais['pre'] = pre\n",
    "nao_funcionais['pre'] = nao_funcionais['pre'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "X_nao_funcionais = nao_funcionais['pre'].tolist()\n",
    "y_nao_funcionais = nao_funcionais['requirement_type'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nao_funcionais, y_nao_funcionais, test_size=0.3, random_state=42)\n",
    "\n",
    "text_classifier_nao_funcionais = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_classifier_nao_funcionais.fit(X_train, y_train)\n",
    "predicted_nao_funcionais = text_classifier_nao_funcionais.predict(X_test)\n",
    "print(classification_report(y_test, predicted_nao_funcionais))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimento 3\n",
    "\n",
    "## Criando datasets balanceados\n",
    "\n",
    "### Funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao    1864\n",
       "sim     928\n",
       "Name: requirement_type, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_array = funcionais[funcionais['requirement_type'] == 'nao'].index\n",
    "funcionais_to_be_removed = np.random.choice(index_array,int(3*len(index_array)/4))\n",
    "\n",
    "funcionais_balanceado = funcionais.drop(funcionais_to_be_removed)\n",
    "funcionais_balanceado['requirement_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Não funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nao    2009\n",
       "sim     509\n",
       "Name: requirement_type, dtype: int64"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_array = nao_funcionais[nao_funcionais['requirement_type'] == 'nao'].index\n",
    "nao_funcionais_to_be_removed = np.random.choice(index_array,int(3*len(index_array)/4))\n",
    "\n",
    "nao_funcionais_balanceado = nao_funcionais.drop(nao_funcionais_to_be_removed)\n",
    "nao_funcionais_balanceado['requirement_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando os classificadores balanceados\n",
    "\n",
    "### Funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nao       0.73      0.99      0.84       577\n",
      "         sim       0.91      0.19      0.32       261\n",
      "\n",
      "   micro avg       0.74      0.74      0.74       838\n",
      "   macro avg       0.82      0.59      0.58       838\n",
      "weighted avg       0.79      0.74      0.68       838\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_pre_review = funcionais_balanceado['reviewText'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "_pre_summary = funcionais_balanceado['summary'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "\n",
    "pre = _pre_review + _pre_summary\n",
    "funcionais_balanceado['pre'] = pre\n",
    "funcionais_balanceado['pre'] = funcionais_balanceado['pre'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "X_funcionais = funcionais_balanceado['pre'].tolist()\n",
    "y_funcionais = funcionais_balanceado['requirement_type'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_funcionais, y_funcionais, test_size=0.3, random_state=42)\n",
    "\n",
    "text_classifier_funcionais_balanceados = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_classifier_funcionais_balanceados.fit(X_train, y_train)\n",
    "predicted_funcionais_balanceados = text_classifier_funcionais_balanceados.predict(X_test)\n",
    "print(classification_report(y_test, predicted_funcionais_balanceados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Não funcionais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         nao       0.79      1.00      0.88       594\n",
      "         sim       1.00      0.01      0.01       162\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       756\n",
      "   macro avg       0.89      0.50      0.45       756\n",
      "weighted avg       0.83      0.79      0.69       756\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_pre_review = nao_funcionais_balanceado['reviewText'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "_pre_summary = nao_funcionais_balanceado['summary'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(remove_stopwords)\n",
    "\n",
    "pre = _pre_review + _pre_summary\n",
    "nao_funcionais_balanceado['pre'] = pre\n",
    "nao_funcionais_balanceado['pre'] = nao_funcionais_balanceado['pre'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "X_nao_funcionais = nao_funcionais_balanceado['pre'].tolist()\n",
    "y_nao_funcionais = nao_funcionais_balanceado['requirement_type'].tolist()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_nao_funcionais, y_nao_funcionais, test_size=0.3, random_state=42)\n",
    "\n",
    "text_classifier_nao_funcionais_balanceados = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf',MultinomialNB()),\n",
    "])\n",
    "\n",
    "text_classifier_nao_funcionais_balanceados.fit(X_train, y_train)\n",
    "predicted_nao_funcionais_balanceados = text_classifier_nao_funcionais_balanceados.predict(X_test)\n",
    "print(classification_report(y_test, predicted_nao_funcionais_balanceados))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict com uso dos classificadores balanceados.\n",
    "\n",
    "\n",
    "# Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_classifier_nao_funcionais_balanceados.predict()\n",
    "# text_classifier_funcionais_balanceados.predict()\n",
    "# pi = pickle.dumps(text_classifier_funcionais_balanceados)\n",
    "\n",
    "with open('../classificadores/text_classifier_nao_funcionais_balanceados', 'wb') as file:\n",
    "    pickle.dump(text_classifier_nao_funcionais_balanceados, file)\n",
    "    \n",
    "with open('../classificadores/text_classifier_funcionais_balanceados', 'wb') as file:\n",
    "    pickle.dump(text_classifier_funcionais_balanceados, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../classificadores/text_classifier_funcionais_balanceados', 'rb') as file:\n",
    "    functional_model = pickle.load(file)\n",
    "    \n",
    "with open('../classificadores/text_classifier_nao_funcionais_balanceados', 'rb') as file:\n",
    "    nao_functional_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/sabinogs/projetos/tcc/dump/test/reviews.bson', 'rb') as b:\n",
    "    new_comments = pd.DataFrame(bson.decode_all(b.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comments_manually_classified = new_comments[new_comments['requirement_type'].isin(['non-functional requirement', 'other', 'functional requirement'])]\n",
    "\n",
    "comments_to_classify = new_comments.drop(comments_manually_classified.index)\n",
    "comments_to_classify = comments_to_classify[['reviewText','summary','requirement_type']]\n",
    "\n",
    "comments_to_classify = comments_to_classify[:5000]\n",
    "_reviewText =  comments_to_classify['reviewText'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(lambda x: ' '.join(x))\n",
    "_summary =  comments_to_classify['summary'].apply(remove_pon).apply(_stem_it).apply(lemmatize_it).apply(lambda x: ' '.join(x))\n",
    "\n",
    "comments_to_classify['pre'] = _reviewText + _summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245.6634"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(comments_to_classify['reviewText'].str.len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_funcional = functional_model.predict(comments_to_classify['pre'])\n",
    "predict_nao_funcional = nao_functional_model.predict(comments_to_classify['pre']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict_nao_funcional\n",
    "comments_to_classify['predict nao funcional'] = predict_nao_funcional\n",
    "comments_to_classify['predict funcional'] = predict_funcional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_multilabel(document):\n",
    "    \n",
    "    if document['predict nao funcional'] == 'sim' and document['predict funcional'] == 'nao':\n",
    "              return 'non-functional requirement'\n",
    "\n",
    "    elif document['predict nao funcional'] == 'nao' and document['predict funcional'] == 'sim':\n",
    "              return 'functional requirement'\n",
    "            \n",
    "    elif document['predict nao funcional'] == 'nao' and document['predict funcional'] == 'nao':\n",
    "              return 'other'\n",
    "    else:\n",
    "        return 'non-functional requirement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['functional requirement', 'other'], dtype=object)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_to_classify['Predicao Intermediaria'] = comments_to_classify.apply(classification_multilabel, axis=1)\n",
    "np.unique(comments_to_classify['Predicao Intermediaria'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                     4709\n",
       "functional requirement     291\n",
       "Name: Predicao Intermediaria, dtype: int64"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_to_classify['Predicao Intermediaria'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['nao'], dtype='<U3')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_nao_funcional)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
