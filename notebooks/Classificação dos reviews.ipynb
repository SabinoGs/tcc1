{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from pymongo import MongoClient\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\n",
    "    '***'\n",
    ")\n",
    "\n",
    "db = client.Downloads\n",
    "collection = db.reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reviews = requests.get('http://127.0.0.1:5000/reviews')\n",
    "\n",
    "all_reviews = list(collection.find().limit(150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame(all_reviews,columns=['reviewText','summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>I love rhapsody. I always used it to listen to...</td>\n",
       "      <td>I love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>I have had it on my cell phone and laptop and ...</td>\n",
       "      <td>Proven Performer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Ok so I get it ok? It's so great and I get a l...</td>\n",
       "      <td>wanna pay...?!?!?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Ipad and Ipod Touch versions are much better. ...</td>\n",
       "      <td>Needs Improvement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>I have been a Rhapsody member for a LONG time ...</td>\n",
       "      <td>All music at one's finger tips</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reviewText  \\\n",
       "145  I love rhapsody. I always used it to listen to...   \n",
       "146  I have had it on my cell phone and laptop and ...   \n",
       "147  Ok so I get it ok? It's so great and I get a l...   \n",
       "148  Ipad and Ipod Touch versions are much better. ...   \n",
       "149  I have been a Rhapsody member for a LONG time ...   \n",
       "\n",
       "                            summary  \n",
       "145                       I love it  \n",
       "146                Proven Performer  \n",
       "147              wanna pay...?!?!?!  \n",
       "148               Needs Improvement  \n",
       "149  All music at one's finger tips  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = reviews[:150]\n",
    "sample.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processamento do texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove_stopwords()**\n",
    "\n",
    "***Argumento***: List(). Lista a qual deseja-se retirar as stopwords na linguagem que deseja. (Linguagem deve ser escrita em inglês)\n",
    "\n",
    "***Retorno***: Lista sem as stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords_sentences(sentences):\n",
    "    word_without_stop = list()\n",
    "    for sent in sentences:\n",
    "        aux = list()\n",
    "        for word in sent:\n",
    "            if word not in stopwords.words('english'):\n",
    "                aux.append(word)\n",
    "        word_without_stop.append(aux)\n",
    "    \n",
    "    return word_without_stop\n",
    "\n",
    "\n",
    "def remove_stopwords(words):\n",
    "    return [word for word in words if word not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**lemmatize_it()**\n",
    "\n",
    "***Argumento***: Lista a qual deseja transformar as palavras em Lemmas (Forma mais básica da palavra original)\n",
    "\n",
    "***Retorno***: Lista de palavras em sua forma mais básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_sentences(sentences):\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    lw = list()\n",
    "    for sent in sentences:\n",
    "        aux = list()\n",
    "        for word in sent:\n",
    "            aux.append(lemma.lemmatize(word))\n",
    "        lw.append(aux)\n",
    "    \n",
    "    return lw\n",
    "\n",
    "def lemmatize_it(words):\n",
    "    lemma = nltk.WordNetLemmatizer()\n",
    "    return [lemma.lemmatize(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pre = sample['reviewText'].apply(nltk.word_tokenize).apply(lemmatize_it).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.concat([sample,pre], axis=1)\n",
    "sample.columns = ['reviewText','summary','pre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_freq_dist(list_of_words):\n",
    "    return nltk.FreqDist(list_of_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ver: \n",
    "***[np.hstack](https://docs.scipy.org/doc/numpy/reference/generated/numpy.hstack.html)***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_of_all_words = np.hstack(sample['pre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from skelearn.feature_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(list_of_all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4613, 1126)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clus = 3\n",
    "\n",
    "km = KMeans(n_clusters=n_clus,max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=200,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_words = np.unique(list_of_all_words).shape[0]\n",
    "order = km.cluster_centers_.argsort()[:,::-1]\n",
    "terms = vectorizer.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster: 0\n",
      "ha\n",
      "zz\n",
      "flash\n",
      "finding\n",
      "fine\n",
      "fire\n",
      "first\n",
      "five\n",
      "fix\n",
      "flexible\n",
      "\n",
      "Cluster: 1\n",
      "great\n",
      "the\n",
      "zz\n",
      "five\n",
      "find\n",
      "finding\n",
      "fine\n",
      "fire\n",
      "first\n",
      "fix\n",
      "\n",
      "Cluster: 2\n",
      "app\n",
      "love\n",
      "rhapsody\n",
      "music\n",
      "use\n",
      "it\n",
      "song\n",
      "like\n",
      "play\n",
      "the\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clus):\n",
    "    print('Cluster: {}'.format(i))\n",
    "    for ind in order[i,:10]:\n",
    "        print(\"{}\".format(terms[ind]))\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
